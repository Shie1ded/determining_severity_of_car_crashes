{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e66e91d0",
      "metadata": {
        "id": "e66e91d0"
      },
      "source": [
        "# Assignment 4: Pipelines and Hyperparameter Tuning (52 total marks)\n",
        "### Due: March 19 at 11:59pm\n",
        "\n",
        "### Name:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a80083d",
      "metadata": {
        "id": "3a80083d"
      },
      "source": [
        "The purpose of this assignment is to practice following the grid-search workflow:\n",
        "- Split data into training and test set\n",
        "- Use the training portion to find the best model using grid search and cross-validation\n",
        "- Retrain the best model\n",
        "- Evaluate the retrained model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "00d7b64f",
      "metadata": {
        "id": "00d7b64f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from yellowbrick.datasets import load_mushroom\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93e1a63",
      "metadata": {
        "id": "c93e1a63"
      },
      "source": [
        "## Part 1: Classification (21 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db693465",
      "metadata": {
        "id": "db693465"
      },
      "source": [
        "### 1.1: Load data (2 marks)\n",
        "For this task, we will be using the yellowbrick mushroom dataset. This dataset uses physical characteristics of mushrooms to predict whether or not the mushroom is poisonous.\n",
        "\n",
        "More information on the dataset can be found here:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/mushroom.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88f8405",
      "metadata": {
        "id": "d88f8405"
      },
      "source": [
        "#### Prepare the feature matrix and target vector\n",
        "\n",
        "Using the yellowbrick `load_mushroom()` function, load the mushroom data set into feature matrix `X` and target vector `y`\n",
        "\n",
        "Print the shape of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library already installed from previous assignments. this is to ensure the\n",
        "# library is installed\n",
        "!pip install yellowbrick"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cVQxofpMRd6",
        "outputId": "1092a8a9-0edb-488d-ce68-9d62681bcb48"
      },
      "id": "5cVQxofpMRd6",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.10/dist-packages (1.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.25.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "df625297",
      "metadata": {
        "id": "df625297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21211656-4d84-405f-87de-f58158d56fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        shape surface   color\n",
            "0      convex  smooth  yellow\n",
            "1        bell  smooth   white\n",
            "2      convex   scaly   white\n",
            "3      convex  smooth    gray\n",
            "4      convex   scaly  yellow\n",
            "...       ...     ...     ...\n",
            "8118  knobbed  smooth   brown\n",
            "8119   convex  smooth   brown\n",
            "8120     flat  smooth   brown\n",
            "8121  knobbed   scaly   brown\n",
            "8122   convex  smooth   brown\n",
            "\n",
            "[8123 rows x 3 columns]\n",
            "-------------------------------\n",
            "0          edible\n",
            "1          edible\n",
            "2       poisonous\n",
            "3          edible\n",
            "4          edible\n",
            "          ...    \n",
            "8118       edible\n",
            "8119       edible\n",
            "8120       edible\n",
            "8121    poisonous\n",
            "8122       edible\n",
            "Name: target, Length: 8123, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "X, y = load_mushroom()\n",
        "\n",
        "# TODO: Print the shape of X and y\n",
        "print(X)\n",
        "print('-------------------------------')\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8af1ddd8",
      "metadata": {
        "id": "8af1ddd8"
      },
      "source": [
        "### 1.2: Pre-processing (3 marks)\n",
        "In this dataset, all the features are categorical, so they need to be encoded. We will use `OneHotEncoder(sparse_output=False)` for this case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "da276a8c",
      "metadata": {
        "id": "da276a8c"
      },
      "outputs": [],
      "source": [
        "# TODO: Create OneHotEncoder object\n",
        "encoder = OneHotEncoder(sparse=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e4f2a89",
      "metadata": {
        "id": "9e4f2a89"
      },
      "source": [
        "The next step is to build a pipeline to combine the encoding with the selected machine learning method. To initialize the pipeline, we will use `LogisticRegression(max_iter=1000)` as a placeholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "edc8d722",
      "metadata": {
        "id": "edc8d722"
      },
      "outputs": [],
      "source": [
        "# TODO: Build the pipeline\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "pipeline = Pipeline([\n",
        "    ('the_encoder', encoder),\n",
        "    ('classifier', logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9776125",
      "metadata": {
        "id": "d9776125"
      },
      "source": [
        "The next step is to split the data into training and testing sets. Use `test_size=0.1, stratify=y, random_state=42`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6ebe1a57",
      "metadata": {
        "id": "6ebe1a57"
      },
      "outputs": [],
      "source": [
        "# TODO: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d3442b",
      "metadata": {
        "id": "77d3442b"
      },
      "source": [
        "### 1.3: Grid Search (4 marks)\n",
        "\n",
        "For the grid search, we would like to test three different models: `LogisticRegression(max_iter=1000)`, `KNeighborsClassifier()` and `SVC()`. Build your parameter grid based on what you think are reasonable values to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "535be88f",
      "metadata": {
        "id": "535be88f"
      },
      "outputs": [],
      "source": [
        "# TODO: Build a parameter grid\n",
        "param_grid_lr = {\n",
        "    'classifier': [LogisticRegression(max_iter=1000)],\n",
        "    'classifier__C': [0.1, 1, 10]\n",
        "}\n",
        "param_grid_kn = {\n",
        "    'classifier': [KNeighborsClassifier()],\n",
        "    'classifier__n_neighbors': [2,4,6]\n",
        "}\n",
        "param_grid_svm = {\n",
        "    'classifier': [SVC()],\n",
        "    'classifier__C': [0.1, 1, 10],\n",
        "    'classifier__kernel': ['linear', 'rbf']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "4fced7ea",
      "metadata": {
        "id": "4fced7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adb39340-f1be-4157-e63a-c6b0acd3de60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('the_encoder',\n",
              "                                        OneHotEncoder(sparse=False)),\n",
              "                                       ('classifier',\n",
              "                                        LogisticRegression(max_iter=1000))]),\n",
              "             param_grid={'classifier': [SVC(C=10)],\n",
              "                         'classifier__C': [0.1, 1, 10],\n",
              "                         'classifier__kernel': ['linear', 'rbf']})"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;the_encoder&#x27;,\n",
              "                                        OneHotEncoder(sparse=False)),\n",
              "                                       (&#x27;classifier&#x27;,\n",
              "                                        LogisticRegression(max_iter=1000))]),\n",
              "             param_grid={&#x27;classifier&#x27;: [SVC(C=10)],\n",
              "                         &#x27;classifier__C&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;classifier__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;the_encoder&#x27;,\n",
              "                                        OneHotEncoder(sparse=False)),\n",
              "                                       (&#x27;classifier&#x27;,\n",
              "                                        LogisticRegression(max_iter=1000))]),\n",
              "             param_grid={&#x27;classifier&#x27;: [SVC(C=10)],\n",
              "                         &#x27;classifier__C&#x27;: [0.1, 1, 10],\n",
              "                         &#x27;classifier__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;the_encoder&#x27;, OneHotEncoder(sparse=False)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# TODO: Implement grid search\n",
        "grid_search_lr = GridSearchCV(pipeline, param_grid_lr, cv=5)\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "grid_search_kn = GridSearchCV(pipeline, param_grid_kn, cv=5)\n",
        "grid_search_kn.fit(X_train, y_train)\n",
        "grid_search_svm = GridSearchCV(pipeline, param_grid_svm, cv=5)\n",
        "grid_search_svm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd6e5f6d",
      "metadata": {
        "id": "fd6e5f6d"
      },
      "source": [
        "### 1.4: Visualize Results (2 marks)\n",
        "\n",
        "The final step is to print out the results from the grid search. You will need to print out the following items:\n",
        "- Best parameters\n",
        "- Best cross-validation train score\n",
        "- Best cross-validation test score\n",
        "- Test set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "97940048",
      "metadata": {
        "id": "97940048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83378779-6f15-4d87-c2b6-2ab2ac789a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:\n",
            "Logistic Regression:\n",
            "\t {'classifier': LogisticRegression(C=1, max_iter=1000), 'classifier__C': 1}\n",
            "KNeighbors Classifier:\n",
            "\t {'classifier': KNeighborsClassifier(n_neighbors=6), 'classifier__n_neighbors': 6}\n",
            "SVC:\n",
            "\t {'classifier': SVC(C=10), 'classifier__C': 10, 'classifier__kernel': 'rbf'}\n",
            "\n",
            "Best Cross-Validation Score:\n",
            "Logistic Regression:\t 0.6693570451436388\n",
            "KNeighbors Classifier:\t 0.6908344733242135\n",
            "SVC:\t\t\t 0.7138166894664842\n",
            "\n",
            "Test set accuracy:\n",
            "Logistic Regression:\t 0.6555965559655597\n",
            "KNeighbors Classifier:\t 0.6691266912669127\n",
            "SVC:\t\t\t 0.6912669126691267\n"
          ]
        }
      ],
      "source": [
        "# TODO: Print the results from the grid search\n",
        "print('Best parameters:')\n",
        "print('Logistic Regression:\\n\\t', grid_search_lr.best_params_)\n",
        "print('KNeighbors Classifier:\\n\\t', grid_search_kn.best_params_)\n",
        "print('SVC:\\n\\t', grid_search_svm.best_params_)\n",
        "\n",
        "print('\\nBest Cross-Validation Score:')\n",
        "print('Logistic Regression:\\t', grid_search_lr.best_score_)\n",
        "print('KNeighbors Classifier:\\t', grid_search_kn.best_score_)\n",
        "print('SVC:\\t\\t\\t', grid_search_svm.best_score_)\n",
        "\n",
        "print('\\nTest set accuracy:')\n",
        "test_lr_accuracy = grid_search_lr.score(X_test, y_test)\n",
        "print('Logistic Regression:\\t', test_lr_accuracy)\n",
        "test_kn_accuracy = grid_search_kn.score(X_test, y_test)\n",
        "print('KNeighbors Classifier:\\t', test_kn_accuracy)\n",
        "test_svm_accuracy = grid_search_svm.score(X_test, y_test)\n",
        "print('SVC:\\t\\t\\t', test_svm_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "337387ca",
      "metadata": {
        "id": "337387ca"
      },
      "source": [
        "### Questions (6 marks)\n",
        "\n",
        "1. Which model and what parameters produced the best results?\n",
        "1. Was this model a good fit? Why or why not?\n",
        "1. Is there anything else we could do to try to improve model performance? Provide two ideas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b171e59d",
      "metadata": {
        "id": "b171e59d"
      },
      "source": [
        "### ANSWERs HERE\n",
        "1. the SVC model with its parameters are produce the best results for the given data\n",
        "2. this model is the best out of the 3 we are using, but it is not a good fit. The SVC has a cross validation score of 71% and a test accuracy of 69%. From this we know that the svc model is consistent as 71 and 69 are a very close fit to one another. with that said this model misses about 30% of the data from the dataset, meaning the model is underfitted when it works with the dataset. this causes the model to miss a large amount of the data from both the training and testing sub-sets meaning it will neglect alot of values which could be useful for later processes\n",
        "3. Yes, the first thing we can do would be to increase the complexity of the model. this will allow it to take more values into a count and increase the cross validation and testing accuracies. Another way to improve the the scores for the model is to configure its hard and soft margins, this will allow the system to ignore any extreme outliers and focus on the more accurate datapoints. with that said, we must be careful to not set the hard margin too aggressively or the model will ignore datapoints which could be valuable for the calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364bac94",
      "metadata": {
        "id": "364bac94"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6a96b7",
      "metadata": {
        "id": "be6a96b7"
      },
      "source": [
        "\n",
        "1. I sourced most of the code from previous assignments/labs plus my memory of working on them. For the OneHotEncoder, I googled it in order to get the basic understanding on how to call it and what it does. I used ChatGPT to decode the setting parameters section.\n",
        "2. I did the assignment in order.\n",
        "3. yes, I used chatGPT to help me figure out how to set the parameters for the Kneighbors classifier. I took the code it gave me and adapted it to my current code.\n",
        "4. the challenge I faced was figuring out how to set the parameters of KNeigbors correctly as well as finding the best scores for the different requirements (i.e cross validation, testing accuracy and best parameters), to solve them I went to Lab 6, which I missed, and looked over it and was able to figure out what to do next"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f5b188",
      "metadata": {
        "id": "b6f5b188"
      },
      "source": [
        "# Part 2: Regression (26 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0af7536",
      "metadata": {
        "id": "a0af7536"
      },
      "source": [
        "For this task, we will be using the auto-mpg dataset. The dataset can be found here: https://archive.ics.uci.edu/ml/datasets/Auto%2BMPG"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ed9025",
      "metadata": {
        "id": "b1ed9025"
      },
      "source": [
        "### 2.1: Load data (3 marks)\n",
        "\n",
        "#### Prepare the feature matrix and target vector\n",
        "\n",
        "Using the code below, load the dataset and separate it into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
        "\n",
        "Print the shape of `X` and `y`\n",
        "\n",
        "**Note that you will need to download the file from D2L or from the UCI website and store it in the same folder as the code for this to work**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library already installed from previous assignments. this is to ensure the\n",
        "# library is installed\n",
        "!pip install ucimlrepo\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aWxpjakrEUl",
        "outputId": "08b327da-a01d-43a0-b136-d8230204e026"
      },
      "id": "_aWxpjakrEUl",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "84fc2a25",
      "metadata": {
        "id": "84fc2a25"
      },
      "outputs": [],
      "source": [
        "# Code to read in the dataset - DO NOT CHANGE\n",
        "data = pd.read_csv('auto-mpg.data',\n",
        "               header=None,\n",
        "              names=[\"mpg\",\n",
        "                    \"cylinders\",\n",
        "                    \"displacement\",\n",
        "                    \"horsepower\",\n",
        "                    \"weight\",\n",
        "                    \"acceleration\",\n",
        "                    \"model_year\",\n",
        "                    \"origin\",\n",
        "                    \"car_name\"],\n",
        "               na_values='?',\n",
        "               sep=r'\\s+')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "1721cf93",
      "metadata": {
        "id": "1721cf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffa71cb-27db-44e2-e82d-33a6b637d67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (398, 7)\n",
            "Shape of y: (398,)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Separate dataset into feature matrix and target vector\n",
        "y = data['mpg']\n",
        "X = data.drop(['mpg','car_name'], axis=1)\n",
        "# TODO: Print shape of X and y\n",
        "print('Shape of X:', X.shape)\n",
        "print('Shape of y:', y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2f08f2",
      "metadata": {
        "id": "9a2f08f2"
      },
      "source": [
        "Do we have any missing values in this case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f9879a8d",
      "metadata": {
        "id": "f9879a8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a11dda-2886-472e-dc12-44a5a73c8d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpg             False\n",
            "cylinders       False\n",
            "displacement    False\n",
            "horsepower       True\n",
            "weight          False\n",
            "acceleration    False\n",
            "model_year      False\n",
            "origin          False\n",
            "car_name        False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "# TODO: Check if there are any missing values\n",
        "missing_values = data.isna().any()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a80ae24c",
      "metadata": {
        "id": "a80ae24c"
      },
      "source": [
        "### 2.2: Pre-processing (5 marks)\n",
        "In this dataset, we have a mixture of categorical and numerical data. This means that we will need to use a `ColumnTransformer()`\n",
        "\n",
        "If you try to use a ColumnTransformer on the data with all the existing features, you will get an error. This is because there are too many unique feature values in the `car_name` column to capture all possible values in the training set. For this assignment, we will remove the `car_name` column to avoid this problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "f0fcb8e0",
      "metadata": {
        "id": "f0fcb8e0"
      },
      "outputs": [],
      "source": [
        "# TODO: Remove car_name column\n",
        "data = data.drop('car_name', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "835893ca",
      "metadata": {
        "id": "835893ca"
      },
      "source": [
        "For this case, we will use:\n",
        "- `OneHotEncoder(sparse_output=False)` for any categorical columns\n",
        "- `StandardScaler()` for any numerical columns\n",
        "- Minimal information imputation for any missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c18db61e",
      "metadata": {
        "id": "c18db61e"
      },
      "outputs": [],
      "source": [
        "# TODO: Create ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# origin_col = ['origin']\n",
        "\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('data_type', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_pipline = Pipeline([\n",
        "    ('data_type', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "        ('num', numerical_pipeline, X),\n",
        "        ('cat', categorical_pipline, ['origin'])\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5be6f5a",
      "metadata": {
        "id": "f5be6f5a"
      },
      "source": [
        "The next step is to build a pipeline to combine the ColumnTransformer with the selected machine learning method. To initialize the pipeline, we will use `LinearRegression()` as a placeholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "57210e6b",
      "metadata": {
        "id": "57210e6b"
      },
      "outputs": [],
      "source": [
        "# TODO: Build the pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# pipeline_models = Pipeline(steps=[\n",
        "#     ('preprocessor', preprocessor),\n",
        "#     ('regression', LinearRegression())\n",
        "# ])\n",
        "pipeline_models = Pipeline(steps=[\n",
        "    ('preprocessor', ColumnTransformer(transformers=[\n",
        "        ('num',\n",
        "         Pipeline(steps=[\n",
        "             ('data_type', SimpleImputer()),\n",
        "             ('scaler', StandardScaler())]),\n",
        "         ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year']),\n",
        "        ('cat',\n",
        "         Pipeline(steps=[\n",
        "             ('data_type', SimpleImputer(strategy='most_frequent')),\n",
        "             ('encoder', OneHotEncoder(sparse_output=False))]),\n",
        "         ['origin'])\n",
        "    ])),\n",
        "    ('regressor', LinearRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1f7ca9",
      "metadata": {
        "id": "9a1f7ca9"
      },
      "source": [
        "The next step is to split the data into training and testing sets. Use `test_size=0.1, random_state=0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "37ee5874",
      "metadata": {
        "id": "37ee5874"
      },
      "outputs": [],
      "source": [
        "# TODO: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f385a6b2",
      "metadata": {
        "id": "f385a6b2"
      },
      "source": [
        "### 2.3: Grid Search (4 marks)\n",
        "\n",
        "For the grid search, we would like to test three different models: `LinearRegression()`, `KNeighborsRegressor()` and `RandomForestRegressor(random_state=0)`. Build your parameter grid based on what you think are reasonable values to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "99936ac0",
      "metadata": {
        "id": "99936ac0"
      },
      "outputs": [],
      "source": [
        "# TODO: Build a parameter grid\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "param_grid_lnr = {\n",
        "    'regressor': [LinearRegression()],\n",
        "}\n",
        "param_grid_knr = {\n",
        "    'regressor': [KNeighborsRegressor()],\n",
        "    'regressor__n_neighbors': [2,4,6],\n",
        "    'regressor__weights': ['uniform', 'distance'],\n",
        "}\n",
        "param_grid_rfr = {\n",
        "    'regressor': [RandomForestRegressor()],\n",
        "    'regressor__n_estimators': [50, 100, 150],\n",
        "    'regressor__max_depth': [None, 10, 20],\n",
        "    'regressor__min_samples_split': [2, 5, 10],\n",
        "    'regressor__min_samples_leaf': [1, 2, 4],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "5a920e2d",
      "metadata": {
        "id": "5a920e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "1c125715-b3d6-4218-8eeb-d8acde8bca45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('preprocessor',\n",
              "                                        ColumnTransformer(transformers=[('num',\n",
              "                                                                         Pipeline(steps=[('data_type',\n",
              "                                                                                          SimpleImputer()),\n",
              "                                                                                         ('scaler',\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         ['cylinders',\n",
              "                                                                          'displacement',\n",
              "                                                                          'horsepower',\n",
              "                                                                          'weight',\n",
              "                                                                          'acceleration',\n",
              "                                                                          'model_year']),\n",
              "                                                                        ('cat',\n",
              "                                                                         Pipeline(steps=[('data_type',\n",
              "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
              "                                                                                         ('encoder',\n",
              "                                                                                          OneHotEncoder(sparse_output=False))]),\n",
              "                                                                         ['origin'])])),\n",
              "                                       ('regressor', LinearRegression())]),\n",
              "             param_grid={'regressor': [RandomForestRegressor(max_depth=20,\n",
              "                                                             n_estimators=50)],\n",
              "                         'regressor__max_depth': [None, 10, 20],\n",
              "                         'regressor__min_samples_leaf': [1, 2, 4],\n",
              "                         'regressor__min_samples_split': [2, 5, 10],\n",
              "                         'regressor__n_estimators': [50, 100, 150]})"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                                         Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                                                          SimpleImputer()),\n",
              "                                                                                         (&#x27;scaler&#x27;,\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         [&#x27;cylinders&#x27;,\n",
              "                                                                          &#x27;displacement&#x27;,\n",
              "                                                                          &#x27;horsepower&#x27;,\n",
              "                                                                          &#x27;weight&#x27;,\n",
              "                                                                          &#x27;acceleration&#x27;,\n",
              "                                                                          &#x27;model_year&#x27;]),\n",
              "                                                                        (&#x27;cat&#x27;,\n",
              "                                                                         Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                                         (&#x27;encoder&#x27;,\n",
              "                                                                                          OneHotEncoder(sparse_output=False))]),\n",
              "                                                                         [&#x27;origin&#x27;])])),\n",
              "                                       (&#x27;regressor&#x27;, LinearRegression())]),\n",
              "             param_grid={&#x27;regressor&#x27;: [RandomForestRegressor(max_depth=20,\n",
              "                                                             n_estimators=50)],\n",
              "                         &#x27;regressor__max_depth&#x27;: [None, 10, 20],\n",
              "                         &#x27;regressor__min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;regressor__min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;regressor__n_estimators&#x27;: [50, 100, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                                         Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                                                          SimpleImputer()),\n",
              "                                                                                         (&#x27;scaler&#x27;,\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         [&#x27;cylinders&#x27;,\n",
              "                                                                          &#x27;displacement&#x27;,\n",
              "                                                                          &#x27;horsepower&#x27;,\n",
              "                                                                          &#x27;weight&#x27;,\n",
              "                                                                          &#x27;acceleration&#x27;,\n",
              "                                                                          &#x27;model_year&#x27;]),\n",
              "                                                                        (&#x27;cat&#x27;,\n",
              "                                                                         Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                                         (&#x27;encoder&#x27;,\n",
              "                                                                                          OneHotEncoder(sparse_output=False))]),\n",
              "                                                                         [&#x27;origin&#x27;])])),\n",
              "                                       (&#x27;regressor&#x27;, LinearRegression())]),\n",
              "             param_grid={&#x27;regressor&#x27;: [RandomForestRegressor(max_depth=20,\n",
              "                                                             n_estimators=50)],\n",
              "                         &#x27;regressor__max_depth&#x27;: [None, 10, 20],\n",
              "                         &#x27;regressor__min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;regressor__min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;regressor__n_estimators&#x27;: [50, 100, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  (&#x27;scaler&#x27;,\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  [&#x27;cylinders&#x27;, &#x27;displacement&#x27;,\n",
              "                                                   &#x27;horsepower&#x27;, &#x27;weight&#x27;,\n",
              "                                                   &#x27;acceleration&#x27;,\n",
              "                                                   &#x27;model_year&#x27;]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                                  (&#x27;encoder&#x27;,\n",
              "                                                                   OneHotEncoder(sparse_output=False))]),\n",
              "                                                  [&#x27;origin&#x27;])])),\n",
              "                (&#x27;regressor&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;data_type&#x27;, SimpleImputer()),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;cylinders&#x27;, &#x27;displacement&#x27;, &#x27;horsepower&#x27;,\n",
              "                                  &#x27;weight&#x27;, &#x27;acceleration&#x27;, &#x27;model_year&#x27;]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;data_type&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;encoder&#x27;,\n",
              "                                                  OneHotEncoder(sparse_output=False))]),\n",
              "                                 [&#x27;origin&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;cylinders&#x27;, &#x27;displacement&#x27;, &#x27;horsepower&#x27;, &#x27;weight&#x27;, &#x27;acceleration&#x27;, &#x27;model_year&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;origin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# TODO: Implement Grid Search\n",
        "grid_search_lnr = GridSearchCV(pipeline_models, param_grid_lnr, cv=5)\n",
        "grid_search_lnr.fit(X_train, y_train)\n",
        "grid_search_knr = GridSearchCV(pipeline_models, param_grid_knr, cv=5)\n",
        "grid_search_knr.fit(X_train, y_train)\n",
        "grid_search_rfr = GridSearchCV(pipeline_models, param_grid_rfr, cv=5)\n",
        "grid_search_rfr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63bc782",
      "metadata": {
        "id": "d63bc782"
      },
      "source": [
        "### 2.4: Visualize Results (2 marks)\n",
        "\n",
        "The final step is to print out the results from the grid search. You will need to print out the following items:\n",
        "- Best parameters\n",
        "- Best cross-validation train score\n",
        "- Best cross-validation test score\n",
        "- Test set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "8aea6dde",
      "metadata": {
        "id": "8aea6dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70fa1864-e630-4187-e9af-b41b5b3bf9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:\n",
            "Linear Regression:\n",
            "\t {'regressor': LinearRegression()}\n",
            "KNeighbors Regression:\n",
            "\t {'regressor': KNeighborsRegressor(n_neighbors=6, weights='distance'), 'regressor__n_neighbors': 6, 'regressor__weights': 'distance'}\n",
            "Random Forest Regression:\n",
            "\t {'regressor': RandomForestRegressor(max_depth=20, n_estimators=50), 'regressor__max_depth': 20, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 50}\n",
            "\n",
            "Best Cross-Validation Score:\n",
            "Linear Regression:\t\t 0.8051113323772965\n",
            "KNeighbors Regression:\t\t 0.8417410474764548\n",
            "Random Forest Regression:\t 0.8510101045331651\n",
            "\n",
            "Test set accuracy:\n",
            "Linear Regression:\t\t 0.8449024450695694\n",
            "KNeighbors Regression:\t\t 0.9058461419712156\n",
            "Random Forest Regression:\t 0.9133858104572892\n"
          ]
        }
      ],
      "source": [
        "# TODO: Print the results from the grid search\n",
        "print('Best parameters:')\n",
        "print('Linear Regression:\\n\\t', grid_search_lnr.best_params_)\n",
        "print('KNeighbors Regression:\\n\\t', grid_search_knr.best_params_)\n",
        "print('Random Forest Regression:\\n\\t', grid_search_rfr.best_params_)\n",
        "\n",
        "print('\\nBest Cross-Validation Score:')\n",
        "print('Linear Regression:\\t\\t', grid_search_lnr.best_score_)\n",
        "print('KNeighbors Regression:\\t\\t', grid_search_knr.best_score_)\n",
        "print('Random Forest Regression:\\t', grid_search_rfr.best_score_)\n",
        "\n",
        "print('\\nTest set accuracy:')\n",
        "test_lnr_accuracy = grid_search_lnr.score(X_test, y_test)\n",
        "print('Linear Regression:\\t\\t', test_lnr_accuracy)\n",
        "test_knr_accuracy = grid_search_knr.score(X_test, y_test)\n",
        "print('KNeighbors Regression:\\t\\t', test_knr_accuracy)\n",
        "test_rfr_accuracy = grid_search_rfr.score(X_test, y_test)\n",
        "print('Random Forest Regression:\\t', test_rfr_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "734a296a",
      "metadata": {
        "id": "734a296a"
      },
      "source": [
        "### Questions (8 marks)\n",
        "\n",
        "1. Which model and what parameters produced the best results?\n",
        "1. Was this model a good fit? Why or why not?\n",
        "1. Is there anything else we could do to try to improve model performance? Provide two ideas (must be different than the two ideas given for the previous part).\n",
        "1. Comparing the two parts, which one took longer to run the grid search? Why do you think it took longer?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6817d521",
      "metadata": {
        "id": "6817d521"
      },
      "source": [
        "1. the model and parameters which produce the best results are Random Forest Regression.\n",
        "\n",
        "2. Yes Random Forest Regression is a good fit. The values for both the cross validation and test accuracy are fairly high, the values are close to each other meaning that the model fits the data well.\n",
        "\n",
        "3. some of the ways we could improve the scores of the testing accuracy and cross validation is to tune the hyperparameters in order to better fit the database. The other possibility is to apply some pre-processing in order to help clean up the data which will help prevent the random forest regressor from overfitting the data.\n",
        "\n",
        "4. the Random Forest regression took much longer to run in comparisons to the linear regression and KNeighbor regression. The reason is because of the way RandomForest regression works. since the regression goes through data in the format of tree diagrams it means that it has to go through every single value and their equivalent branches. this type of work, though more accurate, takes a long time since the system has to cycle back and fourth through the different brancheds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e5af3ca",
      "metadata": {
        "id": "7e5af3ca"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23fb89c8",
      "metadata": {
        "id": "23fb89c8"
      },
      "source": [
        "1. most of the code was sourced from previous assignments/lab, some of the examples used during lectures, and from my memory. I used the colab AI to help me debug parts of the code.\n",
        "\n",
        "2. I finished the code in order\n",
        "\n",
        "3. I used the Colab AI feature in order to help me debug the pipeline part of the system. It helped me take the code from the previous section and help implement it in the correct format so that it will not cause any errors when the code gets to the implementation section\n",
        "\n",
        "4. Other than struggling to get the pipeline to work as stated above, the rest of the code was fairly successful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2eb4f2d",
      "metadata": {
        "id": "d2eb4f2d"
      },
      "source": [
        "## Part 3: Observations/Interpretation (3 marks)\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "A pattern I noticed when working on the system was that for each section of the code, the algorithms used were fairly close to one another in terms of values. which made me really consider which algorithm is best. at the end i chose to ignore the time it takes for each system to run and focus only on the true values since the datasets we are using are not as large. If i had to run different datasets which contained more datapoints i might have to reconsider which algorithm to choose.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "109e6bcd",
      "metadata": {
        "id": "109e6bcd"
      },
      "source": [
        "## Part 4: Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "I liked the format of the assignment as per usual. the flow of the structure makes sense and helps simply each step rather than overwhelm with one empty section to write all the code at once. i found it challenging to get the pipelines figured out. I had to go to lab 6 and learn all what i missed two weeks ago, and thus took me longer to complete the assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81ecdc3",
      "metadata": {
        "id": "b81ecdc3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}